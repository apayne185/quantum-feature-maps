{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5803032",
   "metadata": {},
   "source": [
    "# Data Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2180d967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048cf80d",
   "metadata": {},
   "source": [
    "**Hybrid preprocessing for vision**\n",
    "\n",
    "compare a tiny variational feature map (≤4 qubits on a simulator or IBM device) against a classical baseline on a toy dataset; treat it as a learning exercise in data encoding, noise, and cost models rather than “quantum beats classical.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6a04037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example vector:  tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2000, 0.6235, 0.9922,\n",
      "         0.6235, 0.1961, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1882, 0.9333, 0.9882, 0.9882,\n",
      "         0.9882, 0.9294, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.2118, 0.8902, 0.9922, 0.9882, 0.9373,\n",
      "         0.9137, 0.9882, 0.2235, 0.0235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0392, 0.2353, 0.8784, 0.9882, 0.9922, 0.9882, 0.7922,\n",
      "         0.3294, 0.9882, 0.9922, 0.4784, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.6392, 0.9882, 0.9882, 0.9882, 0.9922, 0.9882, 0.9882,\n",
      "         0.3765, 0.7412, 0.9922, 0.6549, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.2000, 0.9333, 0.9922, 0.9922, 0.7451, 0.4471, 0.9922, 0.8941,\n",
      "         0.1843, 0.3098, 1.0000, 0.6588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.1882, 0.9333, 0.9882, 0.9882, 0.7020, 0.0471, 0.2941, 0.4745, 0.0824,\n",
      "         0.0000, 0.0000, 0.9922, 0.9529, 0.1961, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1490,\n",
      "         0.6471, 0.9922, 0.9137, 0.8157, 0.3294, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.9922, 0.9882, 0.6471, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0275, 0.6980,\n",
      "         0.9882, 0.9412, 0.2784, 0.0745, 0.1098, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.9922, 0.9882, 0.7647, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2235, 0.9882,\n",
      "         0.9882, 0.2471, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.9922, 0.9882, 0.7647, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7765, 0.9922,\n",
      "         0.7451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.9922, 0.7686, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2980, 0.9647, 0.9882,\n",
      "         0.4392, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.9922, 0.9882, 0.5804, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3333, 0.9882, 0.9020,\n",
      "         0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0275, 0.5294, 0.9922, 0.7294, 0.0471, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3333, 0.9882, 0.8745,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0275,\n",
      "         0.5137, 0.9882, 0.8824, 0.2784, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3333, 0.9882, 0.5686,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1882, 0.6471,\n",
      "         0.9882, 0.6784, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3373, 0.9922, 0.8824,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4471, 0.9333, 0.9922,\n",
      "         0.6353, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3333, 0.9882, 0.9765,\n",
      "         0.5725, 0.1882, 0.1137, 0.3333, 0.6980, 0.8824, 0.9922, 0.8745, 0.6549,\n",
      "         0.2196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3333, 0.9882, 0.9882,\n",
      "         0.9882, 0.8980, 0.8431, 0.9882, 0.9882, 0.9882, 0.7686, 0.5098, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1098, 0.7804, 0.9882,\n",
      "         0.9882, 0.9922, 0.9882, 0.9882, 0.9137, 0.5686, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0980, 0.5020,\n",
      "         0.9882, 0.9922, 0.9882, 0.5529, 0.1451, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]])\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([          #chains multiple transformations \n",
    "    transforms.Resize((8,8)),    #downsampling  from 28x28 -> 8x8 so features stay small -64\n",
    "    transforms.ToTensor(),     #transforms data to tensor\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='data', train=True, download=True, transform=transform)     #60000 labeled images\n",
    "test_dataset = datasets.MNIST(root='data', train=False, download=True, transform=transform)     #10000 labeled images \n",
    "\n",
    "#because we are filtering the MNIST dataset for only 0/1s not 0-9\n",
    "train_idx = (train_dataset.targets==0) | (train_dataset.targets==1)\n",
    "test_idx = (test_dataset.targets==0) | (test_dataset.targets==1)\n",
    "\n",
    "\n",
    "X_train = train_dataset.data[train_idx].float() / 255.0  #normalizes to [0,1]   \n",
    "y_train = train_dataset.targets[train_idx]     \n",
    "X_test = test_dataset.data[test_idx].float() / 255.0\n",
    "y_test = test_dataset.targets[test_idx]  \n",
    "\n",
    "print(\"\\nExample vector: \", X_train[0])  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01e40bd",
   "metadata": {},
   "source": [
    "#### Flatten Images\n",
    "multidimensonal images take up more space than a big 1d array, reduces time to run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40bd9c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattened shape xtrain:  torch.Size([12665, 784])\n",
      "flattened shape xtest:  torch.Size([12665, 784])\n",
      "\n",
      "Example vector:  tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.2000, 0.6235, 0.9922, 0.6235, 0.1961, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.1882, 0.9333, 0.9882, 0.9882, 0.9882, 0.9294, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.2118, 0.8902, 0.9922, 0.9882, 0.9373, 0.9137, 0.9882, 0.2235,\n",
      "        0.0235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0392, 0.2353, 0.8784, 0.9882, 0.9922, 0.9882, 0.7922, 0.3294, 0.9882,\n",
      "        0.9922, 0.4784, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.6392, 0.9882, 0.9882, 0.9882, 0.9922, 0.9882, 0.9882, 0.3765,\n",
      "        0.7412, 0.9922, 0.6549, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.2000, 0.9333, 0.9922, 0.9922, 0.7451, 0.4471, 0.9922, 0.8941,\n",
      "        0.1843, 0.3098, 1.0000, 0.6588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.1882, 0.9333, 0.9882, 0.9882, 0.7020, 0.0471, 0.2941, 0.4745,\n",
      "        0.0824, 0.0000, 0.0000, 0.9922, 0.9529, 0.1961, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.1490, 0.6471, 0.9922, 0.9137, 0.8157, 0.3294, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.9922, 0.9882, 0.6471, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0275, 0.6980, 0.9882, 0.9412, 0.2784, 0.0745, 0.1098, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9922, 0.9882, 0.7647, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.2235, 0.9882, 0.9882, 0.2471, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9922, 0.9882, 0.7647,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.7765, 0.9922, 0.7451, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.9922,\n",
      "        0.7686, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.2980, 0.9647, 0.9882, 0.4392, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9922,\n",
      "        0.9882, 0.5804, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.3333, 0.9882, 0.9020, 0.0980, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0275, 0.5294,\n",
      "        0.9922, 0.7294, 0.0471, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3333, 0.9882, 0.8745, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0275, 0.5137,\n",
      "        0.9882, 0.8824, 0.2784, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3333, 0.9882, 0.5686,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1882, 0.6471,\n",
      "        0.9882, 0.6784, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3373, 0.9922,\n",
      "        0.8824, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4471, 0.9333,\n",
      "        0.9922, 0.6353, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3333,\n",
      "        0.9882, 0.9765, 0.5725, 0.1882, 0.1137, 0.3333, 0.6980, 0.8824, 0.9922,\n",
      "        0.8745, 0.6549, 0.2196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.3333, 0.9882, 0.9882, 0.9882, 0.8980, 0.8431, 0.9882, 0.9882, 0.9882,\n",
      "        0.7686, 0.5098, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.1098, 0.7804, 0.9882, 0.9882, 0.9922, 0.9882, 0.9882, 0.9137,\n",
      "        0.5686, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0980, 0.5020, 0.9882, 0.9922, 0.9882, 0.5529,\n",
      "        0.1451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000])\n"
     ]
    }
   ],
   "source": [
    "X_train_flat = X_train.view(X_train.shape[0], -1)  #shape is now (N_sampels, 64)  \n",
    "X_test_flat = X_test.view(X_test.shape[0], -1)   \n",
    "\n",
    "print(\"flattened shape xtrain: \", X_train_flat.shape)\n",
    "print(\"flattened shape xtest: \", X_train_flat.shape)\n",
    "\n",
    "print(\"\\nExample vector: \", X_train_flat[0])  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a147dc45",
   "metadata": {},
   "source": [
    "### Normalize Data\n",
    "\n",
    "Done to ensure feature magnitudes are not too large, as training parameters will take longer (in future steps) if this is not done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25503e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ss = StandardScaler().fit_transform(X_train_flat)\n",
    "X_test_ss = StandardScaler().fit_transform(X_test_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6aa842",
   "metadata": {},
   "source": [
    "### PCA - principal component analysis\n",
    "reduces to <= 4 features for 4 qubits, makes analysis simpler (reduces large num of variables to small num of factors/dimenson reduction)\n",
    "\n",
    "identifies patterns/subsets that have highest correlation to principal amount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8ff74c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA reduced shape xtrain:   (12665, 4)\n",
      "PCA reduced shape xtest:   (2115, 4)\n",
      "ytrain labels:  torch.Size([12665])\n",
      "ytest labels:  torch.Size([2115])\n",
      "\n",
      "Example vector:  [-8.31395886 -6.09814717 -1.37530231 -1.22747553]\n"
     ]
    }
   ],
   "source": [
    "pca= PCA(n_components=4)\n",
    "X_train_pca = pca.fit_transform(X_train_ss)   #fiiting pca to features\n",
    "X_test_pca = pca.transform(X_test_ss)\n",
    "\n",
    "print(\"PCA reduced shape xtrain:  \", X_train_pca.shape)\n",
    "print(\"PCA reduced shape xtest:  \", X_test_pca.shape)\n",
    "print(\"ytrain labels: \", y_train.shape)\n",
    "print(\"ytest labels: \",y_test.shape)\n",
    "\n",
    "print(\"\\nExample vector: \", X_train_pca[0])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07b8eb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12665, 4)\n",
      "False False\n"
     ]
    }
   ],
   "source": [
    "print(X_train_pca.shape)\n",
    "print(np.isnan(X_train_pca).any(), np.isinf(X_train_pca).any())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d25f70b",
   "metadata": {},
   "source": [
    "### Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008bfcd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.font_manager.FontManager at 0x182aaa5b3d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.font_manager._load_fontmanager(try_read_cache=False)\n",
    "\n",
    "#clears the matplotlib font cache to resolve a small error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9df20f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_imgs(imgs, labels):\n",
    "    fig, axes = plt.subplots(1, len(imgs), figsize=(10,2))\n",
    "    for img, label, ax in zip(imgs, labels, axes):\n",
    "        ax.imshow(img.squeeze(), cmap='gray')\n",
    "        ax.set_title(f'Lable:{label}')\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "show_imgs(X_train[:5], y_train[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3038dc66",
   "metadata": {},
   "source": [
    "### Save Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e54e010d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"data/mnist01_pca4.npz\", \n",
    "         X_train=X_train_pca, y_train=y_train.numpy(),\n",
    "         X_test=X_test_pca, y_test=y_test.numpy())     \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qfm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
